{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "!pip install pose_format\n",
    "!pip install sign_language_datasets\n",
    "!pip install tfds-nightly\n",
    "from pose_format import PoseHeader, Pose\n",
    "from pose_format.numpy import NumPyPoseBody\n",
    "from pose_format.utils.reader import BufferReader\n",
    "from tqdm import tqdm\n",
    "from typing import Generator\n",
    "\n",
    "LEXICON_INDEX = ['filename','start', 'end', 'word']\n",
    "\n",
    "\n",
    "def init_index(index_path: str):\n",
    "    if not os.path.isfile(index_path):\n",
    "        # Create csv file with specified header\n",
    "        with open(index_path, 'w', encoding='utf-8', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(LEXICON_INDEX)\n",
    "\n",
    "def load_signsuisse(directory_path: str) -> Generator[Dict[str, str], None, None]:\n",
    "    with open(\"holistic.poseheader\", \"rb\") as buffer:\n",
    "        pose_header = PoseHeader.read(BufferReader(buffer.read()))\n",
    "\n",
    "    # Load dataset (holistic poses?)\n",
    "    from sign_language_datasets.datasets.config import SignDatasetConfig\n",
    "    config = SignDatasetConfig(name=datetime.now().strftime(\"%Y-%m-%d\"), version=\"1.0.0\", include_video=False, include_pose=\"holistic\")\n",
    "    import tensorflow_datasets as tfds\n",
    "    dataset = tfds.load(name='asl_signs', builder_kwargs={\"config\": config})\n",
    "\n",
    "    # Iterate over dataset\n",
    "    for datum in tqdm(dataset[\"train\"]):\n",
    "        uid_raw = datum['id'].numpy().decode('utf-8')\n",
    "        words = datum['name'].numpy().decode('utf-8')\n",
    "\n",
    "        # Load pose and save to file\n",
    "        tf_pose = datum['pose']\n",
    "        fps = int(tf_pose[\"fps\"].numpy())\n",
    "        if fps == 0:\n",
    "            continue\n",
    "        pose_body = NumPyPoseBody(fps, tf_pose[\"data\"].numpy(), tf_pose[\"conf\"].numpy())\n",
    "        pose = Pose(pose_header, pose_body)\n",
    "\n",
    "\n",
    "        with open(os.path.join(directory_path, f\"{uid_raw}.pose\"), \"wb\") as f:\n",
    "            pose.write(f)\n",
    "\n",
    "        yield {\n",
    "            'filename': f\"{uid_raw}.pose\",\n",
    "            'word': words,\n",
    "            'start': \"0\",\n",
    "            'end': str(len(pose_body.data) / fps),  # pose duration\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def add_data(data: List[Dict[str, str]], directory: str):\n",
    "    index_path = os.path.join(directory, 'index.csv')\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    init_index(index_path)\n",
    "\n",
    "    with open(index_path, 'a', encoding='utf-8', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in tqdm(data):\n",
    "            writer.writerow([row[key] for key in LEXICON_INDEX])\n",
    "\n",
    "    print(f\"Added entries to {index_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = load_signsuisse(\"dir\")\n",
    "    add_data(data, \"dir\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
